{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split : seperate the 'fraud' amount from the 'normal' amount\n",
    "\n",
    "By seperating the amount by the class label, we will make models for each type of amount given the class label.''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerrysun/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/jerrysun/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data_reg = data.copy()\n",
    "data_reg.drop(['Time'], axis=1, inplace=True)\n",
    "data_reg['log_amount'] = np.log(list(data_reg['Amount'] + 1))\n",
    "data_reg.drop('Amount', axis=1, inplace=True)\n",
    "\n",
    "normal_data = data_reg[data['Class'] == 0]\n",
    "normal_data.drop(['Class'], axis=1, inplace=True)\n",
    "fraud_data = data_reg[data['Class'] == 1]\n",
    "fraud_data.drop(['Class'], axis=1, inplace=True)\n",
    "# fraud_data\n",
    "\n",
    "normal_y = normal_data['log_amount']\n",
    "fraud_y = fraud_data['log_amount']\n",
    "\n",
    "normal_X = normal_data.drop('log_amount', axis=1)\n",
    "fraud_X = fraud_data.drop('log_amount', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(182)\n",
    "msk = np.random.rand(len(normal_data)) < 0.75\n",
    "normal_train = normal_data[msk]\n",
    "normal_test = normal_data[~msk]\n",
    "# normal_train.shape, normal_test.shape\n",
    "\n",
    "normal_X_train = normal_train.drop('log_amount', axis=1)\n",
    "normal_y_train = normal_train['log_amount']\n",
    "\n",
    "normal_X_test = normal_test.drop('log_amount', axis=1)\n",
    "normal_y_test = normal_test['log_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(fraud_data)) < 0.75\n",
    "fraud_train = fraud_data[msk]\n",
    "fraud_test = fraud_data[~msk]\n",
    "\n",
    "fraud_X_train = fraud_train.drop('log_amount', axis=1)\n",
    "fraud_y_train = fraud_train['log_amount']\n",
    "\n",
    "fraud_X_test = fraud_test.drop('log_amount', axis=1)\n",
    "fraud_y_test = fraud_test['log_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-implemented regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\" The self-implemented LinearRegression class that can do multivarible linear regression. The three functions\n",
    "        we choose to implement is fit, predict, and score and these three methods will make the LinearRegression\n",
    "        function well. X and y have to be np.arrays.\n",
    "        \n",
    "        Methods\n",
    "        -------\n",
    "        fit(self, X, y): fit the train set given the response y\n",
    "        predict(self, X): give the prediction for X\n",
    "        score(self, X, y): give the r^2 given the input of X and the correct output as a measure of the performance\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.betas = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #add a column of ones for the coeffcient\n",
    "        n = X.shape[0]\n",
    "        ones_col = np.ones((n, 1))\n",
    "        X = np.concatenate((ones_col, X), axis=1)\n",
    "        \n",
    "        # the formula: beta = (X^T * X)^-1 * X^T * y\n",
    "        self.betas = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #add a column of ones for the coeffcient\n",
    "        n = X.shape[0]\n",
    "        ones_col = np.ones((n, 1))\n",
    "        X = np.concatenate((ones_col, X), axis=1)\n",
    "        y_hat = np.dot(X, self.betas)\n",
    "        return y_hat\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        if len(y_hat) != len(y):\n",
    "            raise ValueError('Unequal length between the predictions and the true value.')\n",
    "            \n",
    "        y_mean = np.mean(y)\n",
    "        SSE = 0\n",
    "        SST = 0\n",
    "        for i in range(len(y_hat)):\n",
    "            SST += (y[i] - y_mean)**2\n",
    "            SSE += (y[i] - y_hat[i])**2\n",
    "        return 1 - SSE / SST\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Linear Regresion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ridge:\n",
    "    \"\"\" The self-implemented Ridge class that can do multivarible Ridge regression with penalization lambda. The \n",
    "        three functions. We choose to implement is fit, predict, and score and these three methods will make the \n",
    "        LinearRegression function well. X and y have to be np.arrays.\n",
    "        \n",
    "        Methods\n",
    "        -------\n",
    "        fit(self, X, y): fit the train set given the response y\n",
    "        predict(self, X): give the prediction for X\n",
    "        score(self, X, y): give the r^2 given the input of X and the correct output as a measure of the performance\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.betas = []\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #add a column of ones for the coeffcient\n",
    "        n = X.shape[0]\n",
    "        ones_col = np.ones((n, 1))\n",
    "        X = np.concatenate((ones_col, X), axis=1)\n",
    "        \n",
    "        # construct an identity gamma\n",
    "        n = X.shape[1]\n",
    "        gamma = self.alpha * np.identity(n)\n",
    "        \n",
    "        self.betas = np.dot(np.linalg.pinv(X.T @ X + gamma.T @ gamma),X.T @ y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #add a column of ones for the coeffcient\n",
    "        n = X.shape[0]\n",
    "        ones_col = np.ones((n, 1))\n",
    "        X = np.concatenate((ones_col, X), axis=1)\n",
    "        y_hat = np.dot(X, self.betas)\n",
    "        return y_hat\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        if len(y_hat) != len(y):\n",
    "            raise ValueError('Unequal length between the predictions and the true value.')\n",
    "            \n",
    "        y_mean = np.mean(y)\n",
    "        SSE = 0\n",
    "        SST = 0\n",
    "        for i in range(len(y_hat)):\n",
    "            SST += (y[i] - y_mean)**2\n",
    "            SSE += (y[i] - y_hat[i])**2\n",
    "        return 1 - SSE / SST\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Ridge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNNRegressor:\n",
    "    \"\"\" The Self-implemented KNN model take in the train set and use that as the database. To predict, the model\n",
    "        will calculate K nearest neighbor based on the distance metric (for instance, Euclidean distance) and\n",
    "        average the output to give the prediction.\n",
    "        \n",
    "        Methods\n",
    "        -------\n",
    "        fit: fit the model by storing the entire train\n",
    "        predict: based on how many neighbors to use the model yeild the prediction\n",
    "        score(self, X, y): give the r^2 given the input of X and the correct output as a measure of the performance \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "        self.X = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def predict(self, X_predict):\n",
    "        # final prediction\n",
    "        y_hat = []\n",
    "        # Calculate the distance for each input observation\n",
    "        for index, x_predict in enumerate(X_predict):\n",
    "            distance_index = {}\n",
    "            for index, x_train in enumerate(self.X):\n",
    "                distance_index[self._distance(x_predict, x_train)] = index\n",
    "            distance_values = sorted(distance_index.keys())\n",
    "            y_hat_predictions = []\n",
    "            for i in range(self.K):\n",
    "                y_hat_predictions.append(self.y[distance_index[distance_values[i]]])\n",
    "            y_hat.append(np.mean(y_hat_predictions))\n",
    "        return y_hat\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        if len(y_hat) != len(y):\n",
    "            raise ValueError('Unequal length between the predictions and the true value.')\n",
    "            \n",
    "        y_mean = np.mean(y)\n",
    "        SSE = 0\n",
    "        SST = 0\n",
    "        for i in range(len(y_hat)):\n",
    "            SST += (y[i] - y_mean)**2\n",
    "            SSE += (y[i] - y_hat[i])**2\n",
    "        return 1 - SSE / SST \n",
    "    \n",
    "    def _distance(self, x1, x2):\n",
    "        if len(x1) != len(x2):\n",
    "            raise ValueError('Vectors are of different length')\n",
    "        sum = 0\n",
    "        for i in range(len(x1)):\n",
    "            sum += (x1[i] - x2[i])**2\n",
    "        return np.sqrt(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the models\n",
    "---\n",
    "### linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction linear regression train score: 0.401224393484\n",
      "Normal Transaction linear regression test score: 0.356168560254\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(normal_X_train.values, normal_y_train.values)\n",
    "normal_train_score = linear_regression.score(normal_X_train.values, normal_y_train.values)\n",
    "normal_test_score = linear_regression.score(normal_X_test.values, normal_y_test.values)\n",
    "print(\"Normal Transaction linear regression train score:\", normal_train_score)\n",
    "print(\"Normal Transaction linear regression test score:\", normal_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(fraud_X_train.values, fraud_y_train.values)\n",
    "fraud_train_score = linear_regression.score(fraud_X_train.values, fraud_y_train.values)\n",
    "fraud_test_score = linear_regression.score(fraud_X_test.values, fraud_y_test.values)\n",
    "print(\"Fraud Transaction linear regression train score:\", fraud_train_score)\n",
    "print(\"Fraud Transaction linear regression test score:\", fraud_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with Cross Validation tuning the penalizing $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tunable parameters of penalization factor lambdas\n",
    "lambdas = [.001,.005,0.01,5,10,50,100,500,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for predicting the normal amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalizing parameter lambda is 0.001\n"
     ]
    }
   ],
   "source": [
    "# Cross validation for predicting the normal amount\n",
    "# split the train into 10 parts to do the cross validation\n",
    "kf = KFold(n_splits = 10)\n",
    "# store the validation score for each lambda\n",
    "validation_scores = []\n",
    "# cross validation\n",
    "for alpha in lambdas:\n",
    "    cur_scores = []\n",
    "    for train_index, test_index in kf.split(normal_X_train):\n",
    "        X_train_10, X_val_10 = normal_X_train.iloc[train_index].values, normal_X_train.iloc[test_index].values\n",
    "        y_train_10, y_val_10 = normal_y_train.iloc[train_index].values, normal_y_train.iloc[test_index].values\n",
    "        ridge = Ridge(alpha)\n",
    "        ridge.fit(X_train_10, y_train_10)\n",
    "        cur_scores.append(ridge.score(X_train_10, y_train_10))\n",
    "    validation_scores.append(np.mean(cur_scores))\n",
    "print('The best penalizing parameter lambda is {}'.format(lambdas[np.argmax(validation_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction Ridge regression train Score: 0.401224393484\n",
      "Normal Transaction Ridge regression test Score: 0.356168560254\n"
     ]
    }
   ],
   "source": [
    "# Fit the Ridge regression with the lambda giving the best cross validation scores\n",
    "ridge_regression = Ridge(0.001)\n",
    "ridge_regression.fit(normal_X_train.values, normal_y_train.values)\n",
    "print(\"Normal Transaction Ridge regression train Score:\", ridge_regression.score(normal_X_train.values, normal_y_train.values))\n",
    "print(\"Normal Transaction Ridge regression test Score:\", ridge_regression.score(normal_X_test.values, normal_y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for predicting the fraud amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalizing parameter lambda is 0.001\n"
     ]
    }
   ],
   "source": [
    "# Cross validation for predicting the normal amount\n",
    "# split the train into 10 parts to do the cross validation\n",
    "kf = KFold(n_splits = 10)\n",
    "# store the validation score for each lambda\n",
    "validation_scores = []\n",
    "# cross validation\n",
    "for alpha in lambdas:\n",
    "    cur_scores = []\n",
    "    for train_index, test_index in kf.split(fraud_X_train):\n",
    "        X_train_10, X_val_10 = fraud_X_train.iloc[train_index].values, fraud_X_train.iloc[test_index].values\n",
    "        y_train_10, y_val_10 = fraud_y_train.iloc[train_index].values, fraud_y_train.iloc[test_index].values\n",
    "        ridge = Ridge(alpha)\n",
    "        ridge.fit(X_train_10, y_train_10)\n",
    "        cur_scores.append(ridge.score(X_train_10, y_train_10))\n",
    "    validation_scores.append(np.mean(cur_scores))\n",
    "print('The best penalizing parameter lambda is {}'.format(lambdas[np.argmax(validation_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction Ridge regression train Score: 0.640395208557\n",
      "Normal Transaction Ridge regression test Score: 0.518157718729\n"
     ]
    }
   ],
   "source": [
    "# Fit the Ridge regression with the lambda giving the best cross validation scores\n",
    "ridge_regression = Ridge(0.001)\n",
    "ridge_regression.fit(fraud_X_train.values, fraud_y_train.values)\n",
    "print(\"Normal Transaction Ridge regression train Score:\", ridge_regression.score(fraud_X_train.values, fraud_y_train.values))\n",
    "print(\"Normal Transaction Ridge regression test Score:\", ridge_regression.score(fraud_X_test.values, fraud_y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "We use the built in package from sklearn to perform Lasso Regression on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction Lasso regression train Score: 0.399679122735\n",
      "Normal Transaction Lasso regression test Score: 0.356152158435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_regression = LassoCV(alphas=lambdas, fit_intercept=True)\n",
    "lasso_regression.fit(normal_X_train, normal_y_train)\n",
    "\n",
    "print(\"Normal Transaction Lasso regression train Score:\", lasso_regression.score(normal_X_train, normal_y_train))\n",
    "print(\"Normal Transaction Lasso regression test Score:\", lasso_regression.score(normal_X_test, normal_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction Lasso regression train Score: 0.639108711423\n",
      "Fraud Transaction Lasso regression test Score: 0.522291864353\n"
     ]
    }
   ],
   "source": [
    "lasso_regression = LassoCV(alphas=lambdas, fit_intercept=True)\n",
    "lasso_regression.fit(fraud_X_train, fraud_y_train)\n",
    "\n",
    "print(\"Fraud Transaction Lasso regression train Score:\", lasso_regression.score(fraud_X_train, fraud_y_train))\n",
    "print(\"Fraud Transaction Lasso regression test Score:\", lasso_regression.score(fraud_X_test, fraud_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add polynomial and interation terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_poly = normal_data.copy()\n",
    "fraud_poly = fraud_data.copy()\n",
    "\n",
    "columns = list(normal_poly.columns)\n",
    "predictors = columns[:-1]\n",
    "\n",
    "for predictor in predictors:\n",
    "    for i in range(1,3):\n",
    "        normal_poly[predictor + '_' + str(i)] = normal_poly[predictor]**i\n",
    "        fraud_poly[predictor + '_' + str(i)] = fraud_poly[predictor]**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V24_1</th>\n",
       "      <th>V24_2</th>\n",
       "      <th>V25_1</th>\n",
       "      <th>V25_2</th>\n",
       "      <th>V26_1</th>\n",
       "      <th>V26_2</th>\n",
       "      <th>V27_1</th>\n",
       "      <th>V27_2</th>\n",
       "      <th>V28_1</th>\n",
       "      <th>V28_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.115496</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.027946</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>0.475108</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>0.107349</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>1.381977</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>0.419096</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.049252</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.003777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.042440</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.048146</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.046291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10    ...        V24_1     V24_2     V25_1  \\\n",
       "0  0.098698  0.363787  0.090794    ...     0.066928  0.004479  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974    ...    -0.339846  0.115496  0.167170   \n",
       "2  0.247676 -1.514654  0.207643    ...    -0.689281  0.475108 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952    ...    -1.175575  1.381977  0.647376   \n",
       "4 -0.270533  0.817739  0.753074    ...     0.141267  0.019956 -0.206010   \n",
       "\n",
       "      V25_2     V26_1     V26_2     V27_1     V27_2     V28_1     V28_2  \n",
       "0  0.016522 -0.189115  0.035764  0.133558  0.017838 -0.021053  0.000443  \n",
       "1  0.027946  0.125895  0.015849 -0.008983  0.000081  0.014724  0.000217  \n",
       "2  0.107349 -0.139097  0.019348 -0.055353  0.003064 -0.059752  0.003570  \n",
       "3  0.419096 -0.221929  0.049252  0.062723  0.003934  0.061458  0.003777  \n",
       "4  0.042440  0.502292  0.252297  0.219422  0.048146  0.215153  0.046291  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(normal_poly)) < 0.75\n",
    "normal_poly_train = normal_poly[msk]\n",
    "normal_poly_test = normal_poly[~msk]\n",
    "\n",
    "normal_poly_X_train = normal_poly_train.drop('log_amount', axis=1)\n",
    "normal_poly_y_train = normal_poly_train['log_amount']\n",
    "\n",
    "normal_poly_X_test = normal_poly_test.drop('log_amount', axis=1)\n",
    "normal_poly_y_test = normal_poly_test['log_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(fraud_poly)) < 0.75\n",
    "fraud_poly_train = fraud_poly[msk]\n",
    "fraud_poly_test = fraud_poly[~msk]\n",
    "\n",
    "fraud_poly_X_train = fraud_poly_train.drop('log_amount', axis=1)\n",
    "fraud_poly_y_train = fraud_poly_train['log_amount']\n",
    "\n",
    "fraud_poly_X_test = fraud_poly_test.drop('log_amount', axis=1)\n",
    "fraud_poly_y_test = fraud_poly_test['log_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction linear regression with polynomial terms train score: 0.461756200374\n",
      "Normal Transaction linear regression with polynomial terms test score: 0.447337215489\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(normal_poly_X_train.values, normal_poly_y_train.values)\n",
    "normal_poly_train_score = linear_regression.score(normal_poly_X_train.values, normal_poly_y_train.values)\n",
    "normal_poly_test_score = linear_regression.score(normal_poly_X_test.values, normal_poly_y_test.values)\n",
    "print(\"Normal Transaction linear regression with polynomial terms train score:\", normal_poly_train_score)\n",
    "print(\"Normal Transaction linear regression with polynomial terms test score:\", normal_poly_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction linear regression with polynomial terms train score: 0.72659866445\n",
      "Fraud Transaction linear regression with polynomial terms test score: 0.532846917532\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(fraud_poly_X_train.values, fraud_poly_y_train.values)\n",
    "fraud_poly_train_score = linear_regression.score(fraud_poly_X_train.values, fraud_poly_y_train.values)\n",
    "fraud_poly_test_score = linear_regression.score(fraud_poly_X_test.values, fraud_poly_y_test.values)\n",
    "print(\"Fraud Transaction linear regression with polynomial terms train score:\", fraud_poly_train_score)\n",
    "print(\"Fraud Transaction linear regression with polynomial terms test score:\", fraud_poly_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above statistics we notice that for fraud transaction we have a training socre that is much higher than that of the test set. This is a sign of overfitting so we again choose to perform Ridge and Lasso regression to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression for Linear Regression with Polynomial Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for predicting the normal amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalizing parameter lambda is 0.01\n"
     ]
    }
   ],
   "source": [
    "# Cross validation for predicting the normal amount with polynomial terms\n",
    "# split the train into 10 parts to do the cross validation\n",
    "kf = KFold(n_splits = 10)\n",
    "# store the validation score for each lambda\n",
    "validation_scores = []\n",
    "# cross validation\n",
    "for alpha in lambdas:\n",
    "    cur_scores = []\n",
    "    for train_index, test_index in kf.split(normal_poly_X_train):\n",
    "        X_train_10, X_val_10 = normal_poly_X_train.iloc[train_index].values, normal_poly_X_train.iloc[test_index].values\n",
    "        y_train_10, y_val_10 = normal_poly_y_train.iloc[train_index].values, normal_poly_y_train.iloc[test_index].values\n",
    "        ridge = Ridge(alpha)\n",
    "        ridge.fit(X_train_10, y_train_10)\n",
    "        cur_scores.append(ridge.score(X_train_10, y_train_10))\n",
    "    validation_scores.append(np.mean(cur_scores))\n",
    "print('The best penalizing parameter lambda is {}'.format(lambdas[np.argmax(validation_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction Ridge regression with polynomial terms train score: 0.461756200374\n",
      "Normal Transaction Ridge regression with polynomial terms test score: 0.447337205257\n"
     ]
    }
   ],
   "source": [
    "ridge_regression_poly = Ridge(0.01)\n",
    "ridge_regression_poly.fit(normal_poly_X_train.values, normal_poly_y_train.values)\n",
    "\n",
    "print(\"Normal Transaction Ridge regression with polynomial terms train score:\", \\\n",
    "      ridge_regression_poly.score(normal_poly_X_train.values, normal_poly_y_train.values))#### Cross validation for predicting the normal amount\n",
    "print(\"Normal Transaction Ridge regression with polynomial terms test score:\", \\\n",
    "      ridge_regression_poly.score(normal_poly_X_test.values, normal_poly_y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for predicting the fraud amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalizing parameter lambda is 0.005\n"
     ]
    }
   ],
   "source": [
    "# Cross validation for predicting the normal amount with polynomial terms\n",
    "# split the train into 10 parts to do the cross validation\n",
    "kf = KFold(n_splits = 10)\n",
    "# store the validation score for each lambda\n",
    "validation_scores = []\n",
    "# cross validation\n",
    "for alpha in lambdas:\n",
    "    cur_scores = []\n",
    "    for train_index, test_index in kf.split(fraud_poly_X_train):\n",
    "        X_train_10, X_val_10 = fraud_poly_X_train.iloc[train_index].values, fraud_poly_X_train.iloc[test_index].values\n",
    "        y_train_10, y_val_10 = fraud_poly_y_train.iloc[train_index].values, fraud_poly_y_train.iloc[test_index].values\n",
    "        ridge = Ridge(alpha)\n",
    "        ridge.fit(X_train_10, y_train_10)\n",
    "        cur_scores.append(ridge.score(X_train_10, y_train_10))\n",
    "    validation_scores.append(np.mean(cur_scores))\n",
    "print('The best penalizing parameter lambda is {}'.format(lambdas[np.argmax(validation_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction Ridge regression with polynomial terms train score: 0.714269514911\n",
      "Fraud Transaction Ridge regression with polynomial terms test score: 0.571867805349\n"
     ]
    }
   ],
   "source": [
    "ridge_regression_poly = Ridge(0.005)\n",
    "ridge_regression_poly.fit(fraud_poly_X_train.values, fraud_poly_y_train.values)\n",
    "\n",
    "print(\"Fraud Transaction Ridge regression with polynomial terms train score:\", \\\n",
    "      ridge_regression.score(fraud_poly_X_train.values, fraud_poly_y_train.values))\n",
    "print(\"Fraud Transaction Ridge regression with polynomial terms test score:\", \\\n",
    "      ridge_regression.score(fraud_poly_X_test.values, fraud_poly_y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression for Linear Regression with Polynomial Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction Lasso regression with polynomial terms train score: 0.458631677515\n",
      "Normal Transaction Lasso regression with polynomial terms test score: 0.445074861588\n"
     ]
    }
   ],
   "source": [
    "lasso_regression = LassoCV(alphas=lambdas, fit_intercept=True)\n",
    "lasso_regression.fit(normal_poly_X_train, normal_poly_y_train)\n",
    "\n",
    "print(\"Normal Transaction Lasso regression with polynomial terms train score:\", \\\n",
    "      lasso_regression.score(normal_poly_X_train, normal_poly_y_train))\n",
    "print(\"Normal Transaction Lasso regression with polynomial terms test score:\", \\\n",
    "      lasso_regression.score(normal_poly_X_test, normal_poly_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction Lasso regression with polynomial terms train score: 0.169866327262\n",
      "Fraud Transaction Lasso regression with polynomial terms test score: 0.140171607407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerrysun/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_regression = LassoCV(alphas=lambdas, fit_intercept=True)\n",
    "lasso_regression.fit(fraud_poly_X_train, fraud_poly_y_train)\n",
    "\n",
    "print(\"Fraud Transaction Lasso regression with polynomial terms train score:\", \\\n",
    "      lasso_regression.score(fraud_poly_X_train, fraud_poly_y_train))\n",
    "print(\"Fraud Transaction Lasso regression with polynomial terms test score:\", \\\n",
    "      lasso_regression.score(fraud_poly_X_test, fraud_poly_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors for Fraud Amount using k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud transaction using KNN train score: 0.5752330189704606\n",
      "Fraud transaction using KNN test score: 0.3557295374866566\n"
     ]
    }
   ],
   "source": [
    "# Using the self-implemented KNN for predicting fraud transaction amount\n",
    "knn = KNNRegressor(10)\n",
    "knn.fit(fraud_X_train.values, fraud_y_train.values)\n",
    "print(\"Fraud transaction using KNN train score: {}\".format(knn.score(fraud_X_train.values, fraud_y_train.values)))\n",
    "print(\"Fraud transaction using KNN test score: {}\".format(knn.score(fraud_X_test.values, fraud_y_test.values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
